{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CircuitKV Novel Add-ons PoC: ICML 2026\n",
    "\n",
    "**Goal:** Test CHEAP novel add-ons to RC (Random Circuit) that improve bridge detection.\n",
    "\n",
    "## Novel Ideas (Zero Extra Cost - Just Modify Walker):\n",
    "\n",
    "### 1. **Hitting Time Weighting** (RC+HT)\n",
    "- Weight visits by WHEN in the walk they occur\n",
    "- Early visits (near query) = high recency importance\n",
    "- Late visits (near sink) = high foundational importance\n",
    "- Cost: Zero - just change the atomic add weight\n",
    "\n",
    "### 2. **Escape Probability** (RC+EP)\n",
    "- Track FIRST visit vs TOTAL visits per token\n",
    "- Bridge = you pass through once and escape to sink\n",
    "- Hub = you keep coming back (high revisit ratio)\n",
    "- Cost: +1 bit per walker per token (negligible)\n",
    "\n",
    "### 3. **Absorption Speed** (RC+AS)\n",
    "- Track how fast walkers get absorbed after visiting each token\n",
    "- Fast absorption = direct path to sink = true bridge\n",
    "- Slow absorption = stuck in distractor cluster\n",
    "- Cost: Zero - just track step count\n",
    "\n",
    "### 4. **Temperature Mixing** (RC+TM)\n",
    "- Half walkers use sharp temperature (follow strongest edges)\n",
    "- Half walkers use soft temperature (explore more)\n",
    "- Combines local hub detection + global bridge detection\n",
    "- Cost: Zero - just change softmax scale\n",
    "\n",
    "**Metric:** F1 score on actual generation (same as LongBench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import gc\n",
    "import math\n",
    "\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "MAX_SEQ_LEN = 2048\n",
    "MAX_NEW_TOKENS = 64\n",
    "NUM_SAMPLES = 5\n",
    "BUDGET_RATIO = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score (LongBench metric)\n",
    "def normalize_answer(s: str) -> str:\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    return white_space_fix(remove_articles(remove_punc(s.lower())))\n",
    "\n",
    "def f1_score(prediction: str, ground_truth: str) -> float:\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    gold_tokens = normalize_answer(ground_truth).split()\n",
    "    if len(pred_tokens) == 0 or len(gold_tokens) == 0:\n",
    "        return float(pred_tokens == gold_tokens)\n",
    "    common = Counter(pred_tokens) & Counter(gold_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gold_tokens)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def best_f1(prediction: str, answers: List[str]) -> float:\n",
    "    return max(f1_score(prediction, ans) for ans in answers) if answers else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"Loading model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "model.eval()\n",
    "print(f\"Loaded. GPU: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"THUDM/LongBench\", \"narrativeqa\", split=\"test\", trust_remote_code=True)\n",
    "samples = []\n",
    "for i, item in enumerate(ds):\n",
    "    if i >= NUM_SAMPLES:\n",
    "        break\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Read the following text and answer the question.\n",
    "\n",
    "Text: {item['context']}\n",
    "\n",
    "Question: {item['input']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "    samples.append({\"prompt\": prompt, \"answers\": item[\"answers\"], \"question\": item[\"input\"]})\n",
    "print(f\"Loaded {len(samples)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk Simulation (PyTorch - Simulates CUDA Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_graph(attn_matrix: torch.Tensor, top_k: int = 32) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Build sparse adjacency graph from attention matrix.\n",
    "    Returns: (adj_indices [n, top_k], adj_weights [n, top_k])\n",
    "    \"\"\"\n",
    "    n = attn_matrix.shape[0]\n",
    "    device = attn_matrix.device\n",
    "    \n",
    "    # For each row, get top-k neighbors (causal: only attend to past)\n",
    "    adj_weights = torch.zeros(n, top_k, device=device)\n",
    "    adj_indices = torch.full((n, top_k), -1, dtype=torch.long, device=device)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Only consider tokens 0..i-1 (causal)\n",
    "        if i == 0:\n",
    "            continue\n",
    "        \n",
    "        row = attn_matrix[i, :i]  # Only past tokens\n",
    "        k = min(top_k, i)\n",
    "        \n",
    "        if k > 0:\n",
    "            topk_weights, topk_idx = row.topk(k)\n",
    "            adj_weights[i, :k] = topk_weights\n",
    "            adj_indices[i, :k] = topk_idx\n",
    "    \n",
    "    return adj_indices, adj_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_walks(\n",
    "    adj_indices: torch.Tensor,\n",
    "    adj_weights: torch.Tensor,\n",
    "    source_nodes: List[int],\n",
    "    num_walkers: int = 256,\n",
    "    max_steps: int = 100,\n",
    "    sink_size: int = 4,\n",
    "    mode: str = \"basic\",  # basic, hitting_time, escape_prob, absorption_speed, temp_mix\n",
    "    temperature: float = 1.0,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Run absorbing random walks from source nodes toward sink.\n",
    "    \n",
    "    Modes:\n",
    "    - basic: Standard visit counting (current RC)\n",
    "    - hitting_time: Weight by step number (early = high weight)\n",
    "    - escape_prob: Track first-visit ratio\n",
    "    - absorption_speed: Track absorption time per token\n",
    "    - temp_mix: Mix sharp and soft temperature walkers\n",
    "    \n",
    "    Returns: scores [n]\n",
    "    \"\"\"\n",
    "    n = adj_indices.shape[0]\n",
    "    device = adj_indices.device\n",
    "    \n",
    "    # Initialize score buffers based on mode\n",
    "    visits = torch.zeros(n, device=device)\n",
    "    first_visits = torch.zeros(n, device=device) if mode == \"escape_prob\" else None\n",
    "    absorption_times = torch.zeros(n, device=device) if mode == \"absorption_speed\" else None\n",
    "    absorption_counts = torch.zeros(n, device=device) if mode == \"absorption_speed\" else None\n",
    "    \n",
    "    total_walkers = num_walkers * len(source_nodes)\n",
    "    \n",
    "    for walker_id in range(total_walkers):\n",
    "        # Select source\n",
    "        source_idx = walker_id % len(source_nodes)\n",
    "        pos = source_nodes[source_idx]\n",
    "        \n",
    "        # Per-walker state\n",
    "        visited_this_walk = set() if mode == \"escape_prob\" else None\n",
    "        \n",
    "        # Temperature for this walker (temp_mix mode)\n",
    "        if mode == \"temp_mix\":\n",
    "            # Half walkers use sharp temp, half use soft\n",
    "            temp = 2.0 if walker_id % 2 == 0 else 0.5\n",
    "        else:\n",
    "            temp = temperature\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Record visit based on mode\n",
    "            if mode == \"basic\":\n",
    "                visits[pos] += 1.0\n",
    "            \n",
    "            elif mode == \"hitting_time\":\n",
    "                # Early visits get higher weight\n",
    "                weight = (max_steps - step) / max_steps\n",
    "                visits[pos] += weight\n",
    "            \n",
    "            elif mode == \"escape_prob\":\n",
    "                visits[pos] += 1.0\n",
    "                if pos not in visited_this_walk:\n",
    "                    first_visits[pos] += 1.0\n",
    "                    visited_this_walk.add(pos)\n",
    "            \n",
    "            elif mode == \"absorption_speed\":\n",
    "                visits[pos] += 1.0\n",
    "            \n",
    "            elif mode == \"temp_mix\":\n",
    "                visits[pos] += 1.0\n",
    "            \n",
    "            # Check absorption\n",
    "            if pos < sink_size:\n",
    "                # Record absorption stats\n",
    "                if mode == \"absorption_speed\" and visited_this_walk is None:\n",
    "                    # Track which tokens led to fast absorption\n",
    "                    # (we'll handle this differently)\n",
    "                    pass\n",
    "                break\n",
    "            \n",
    "            # Get neighbors\n",
    "            neighbors = adj_indices[pos]\n",
    "            weights = adj_weights[pos]\n",
    "            \n",
    "            # Filter valid neighbors\n",
    "            valid_mask = neighbors >= 0\n",
    "            if not valid_mask.any():\n",
    "                break\n",
    "            \n",
    "            valid_neighbors = neighbors[valid_mask]\n",
    "            valid_weights = weights[valid_mask]\n",
    "            \n",
    "            # Apply temperature\n",
    "            if temp != 1.0:\n",
    "                valid_weights = valid_weights ** (1.0 / temp)\n",
    "            \n",
    "            # Normalize to probabilities\n",
    "            probs = valid_weights / valid_weights.sum().clamp(min=1e-8)\n",
    "            \n",
    "            # Sample next position\n",
    "            idx = torch.multinomial(probs, 1).item()\n",
    "            pos = valid_neighbors[idx].item()\n",
    "    \n",
    "    # Compute final scores based on mode\n",
    "    if mode == \"escape_prob\":\n",
    "        # Escape ratio = first_visits / total_visits\n",
    "        # High ratio = bridge (pass through once and escape)\n",
    "        # Low ratio = hub (keep coming back)\n",
    "        escape_ratio = first_visits / visits.clamp(min=1.0)\n",
    "        # Combine with visit count (need both signal strength and escape)\n",
    "        scores = escape_ratio * (visits / visits.max().clamp(min=1e-8))\n",
    "    else:\n",
    "        scores = visits\n",
    "    \n",
    "    # Normalize\n",
    "    if scores.max() > 0:\n",
    "        scores = scores / scores.max()\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eviction Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy:\n",
    "    \"\"\"Base class for KV eviction strategies.\"\"\"\n",
    "    def __init__(self, budget_ratio=0.25, sink_size=4, local_window=32, top_k=32):\n",
    "        self.budget_ratio = budget_ratio\n",
    "        self.sink_size = sink_size\n",
    "        self.local_window = local_window\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_keep_indices(self, scores: torch.Tensor, seq_len: int) -> torch.Tensor:\n",
    "        budget = int(seq_len * self.budget_ratio)\n",
    "        device = scores.device\n",
    "        \n",
    "        mask = torch.zeros(seq_len, dtype=torch.bool, device=device)\n",
    "        mask[:self.sink_size] = True\n",
    "        mask[-self.local_window:] = True\n",
    "        \n",
    "        already_kept = mask.sum().item()\n",
    "        remaining = max(0, budget - already_kept)\n",
    "        \n",
    "        if remaining > 0:\n",
    "            scores_masked = scores.clone()\n",
    "            scores_masked[mask] = float('-inf')\n",
    "            _, top_idx = scores_masked.topk(remaining)\n",
    "            mask[top_idx] = True\n",
    "        \n",
    "        return mask.nonzero(as_tuple=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2OStrategy(BaseStrategy):\n",
    "    \"\"\"Baseline: H2O (Heavy Hitter Oracle).\"\"\"\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        W = min(32, attn_matrix.shape[0] - self.sink_size)\n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        return h2o / h2o.max().clamp(min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCStrategy(BaseStrategy):\n",
    "    \"\"\"\n",
    "    RC (Random Circuit): Base absorbing random walk strategy.\n",
    "    This is the current CircuitKV implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_walkers=256, observation_window=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_walkers = num_walkers\n",
    "        self.observation_window = observation_window\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        n = attn_matrix.shape[0]\n",
    "        W = min(self.observation_window, n - self.sink_size)\n",
    "        \n",
    "        # Build sparse graph\n",
    "        adj_indices, adj_weights = build_sparse_graph(attn_matrix, self.top_k)\n",
    "        \n",
    "        # Source nodes = observation window\n",
    "        source_nodes = list(range(n - W, n))\n",
    "        \n",
    "        # Run walks\n",
    "        circuit_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"basic\",\n",
    "        )\n",
    "        \n",
    "        # Combine with H2O\n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        h2o = h2o / h2o.max().clamp(min=1e-8)\n",
    "        \n",
    "        # Union: max of both\n",
    "        return torch.maximum(h2o, circuit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC_HittingTime(RCStrategy):\n",
    "    \"\"\"\n",
    "    RC + Hitting Time Weighting (RC+HT)\n",
    "    \n",
    "    NOVEL: Weight visits by WHEN in the walk they occur.\n",
    "    - Early visits (near query) = high recency weight\n",
    "    - Late visits (near sink) = lower weight\n",
    "    \n",
    "    Insight: Tokens visited early in the walk are closer to the query.\n",
    "    Tokens visited late might be \"detours\" through distractors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        n = attn_matrix.shape[0]\n",
    "        W = min(self.observation_window, n - self.sink_size)\n",
    "        \n",
    "        adj_indices, adj_weights = build_sparse_graph(attn_matrix, self.top_k)\n",
    "        source_nodes = list(range(n - W, n))\n",
    "        \n",
    "        # Run walks with hitting time weighting\n",
    "        circuit_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"hitting_time\",  # <-- Novel modification\n",
    "        )\n",
    "        \n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        h2o = h2o / h2o.max().clamp(min=1e-8)\n",
    "        \n",
    "        return torch.maximum(h2o, circuit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC_EscapeProb(RCStrategy):\n",
    "    \"\"\"\n",
    "    RC + Escape Probability (RC+EP)\n",
    "    \n",
    "    NOVEL: Track first-visit vs total-visit ratio per token.\n",
    "    - High escape ratio = bridge (pass through once, escape to sink)\n",
    "    - Low escape ratio = hub (walkers keep returning)\n",
    "    \n",
    "    Insight: True reasoning bridges are \"one-way streets\" toward sink.\n",
    "    Distractors are \"traps\" that walkers revisit.\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        n = attn_matrix.shape[0]\n",
    "        W = min(self.observation_window, n - self.sink_size)\n",
    "        \n",
    "        adj_indices, adj_weights = build_sparse_graph(attn_matrix, self.top_k)\n",
    "        source_nodes = list(range(n - W, n))\n",
    "        \n",
    "        # Run walks with escape probability tracking\n",
    "        circuit_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"escape_prob\",  # <-- Novel modification\n",
    "        )\n",
    "        \n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        h2o = h2o / h2o.max().clamp(min=1e-8)\n",
    "        \n",
    "        return torch.maximum(h2o, circuit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC_TempMix(RCStrategy):\n",
    "    \"\"\"\n",
    "    RC + Temperature Mixing (RC+TM)\n",
    "    \n",
    "    NOVEL: Run walkers with different \"temperatures\".\n",
    "    - Sharp temp (2.0): Follows strongest edges -> finds local hubs\n",
    "    - Soft temp (0.5): Explores broadly -> finds global bridges\n",
    "    \n",
    "    Insight: Different temperatures capture different importance patterns.\n",
    "    Combining them catches both local and global structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        n = attn_matrix.shape[0]\n",
    "        W = min(self.observation_window, n - self.sink_size)\n",
    "        \n",
    "        adj_indices, adj_weights = build_sparse_graph(attn_matrix, self.top_k)\n",
    "        source_nodes = list(range(n - W, n))\n",
    "        \n",
    "        # Run walks with temperature mixing\n",
    "        circuit_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"temp_mix\",  # <-- Novel modification\n",
    "        )\n",
    "        \n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        h2o = h2o / h2o.max().clamp(min=1e-8)\n",
    "        \n",
    "        return torch.maximum(h2o, circuit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RC_Combined(RCStrategy):\n",
    "    \"\"\"\n",
    "    RC + All Novel Modifications Combined\n",
    "    \n",
    "    Combines: Hitting Time + Escape Probability + Temperature Mixing\n",
    "    Uses max() to keep tokens important on ANY signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_scores(self, attn_matrix: torch.Tensor) -> torch.Tensor:\n",
    "        n = attn_matrix.shape[0]\n",
    "        W = min(self.observation_window, n - self.sink_size)\n",
    "        \n",
    "        adj_indices, adj_weights = build_sparse_graph(attn_matrix, self.top_k)\n",
    "        source_nodes = list(range(n - W, n))\n",
    "        \n",
    "        # Run all modes\n",
    "        ht_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers // 3,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"hitting_time\",\n",
    "        )\n",
    "        \n",
    "        ep_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers // 3,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"escape_prob\",\n",
    "        )\n",
    "        \n",
    "        tm_scores = run_random_walks(\n",
    "            adj_indices, adj_weights, source_nodes,\n",
    "            num_walkers=self.num_walkers // 3,\n",
    "            sink_size=self.sink_size,\n",
    "            mode=\"temp_mix\",\n",
    "        )\n",
    "        \n",
    "        # Combine with max (union)\n",
    "        circuit_scores = torch.maximum(ht_scores, torch.maximum(ep_scores, tm_scores))\n",
    "        \n",
    "        h2o = attn_matrix[-W:, :].sum(dim=0)\n",
    "        h2o = h2o / h2o.max().clamp(min=1e-8)\n",
    "        \n",
    "        return torch.maximum(h2o, circuit_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation with Eviction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_with_strategy(\n",
    "    model, tokenizer, prompt: str,\n",
    "    strategy: Optional[BaseStrategy] = None,\n",
    "    max_length: int = 2048,\n",
    "    max_new_tokens: int = 64,\n",
    ") -> str:\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt, return_tensors=\"pt\", truncation=True,\n",
    "        max_length=max_length - max_new_tokens,\n",
    "    ).to(model.device)\n",
    "    \n",
    "    input_len = inputs.input_ids.shape[1]\n",
    "    \n",
    "    if strategy is None:\n",
    "        # FullKV - no eviction\n",
    "        outputs = model.generate(\n",
    "            **inputs, max_new_tokens=max_new_tokens,\n",
    "            do_sample=False, pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        return tokenizer.decode(outputs[0][input_len:], skip_special_tokens=True).strip()\n",
    "    \n",
    "    # Run prefill to get attention\n",
    "    outputs = model(**inputs, output_attentions=True, use_cache=True)\n",
    "    past_kv = outputs.past_key_values\n",
    "    \n",
    "    # Get attention matrix from last layer, first head\n",
    "    attn = outputs.attentions[-1][0, 0, :, :].float()  # [seq_len, seq_len]\n",
    "    \n",
    "    # Compute importance scores\n",
    "    scores = strategy.compute_scores(attn)\n",
    "    keep_indices = strategy.get_keep_indices(scores, input_len)\n",
    "    \n",
    "    # Evict KV cache\n",
    "    new_past_kv = []\n",
    "    for k, v in past_kv:\n",
    "        new_past_kv.append((k[:, :, keep_indices, :], v[:, :, keep_indices, :]))\n",
    "    new_past_kv = tuple(new_past_kv)\n",
    "    \n",
    "    # Generate\n",
    "    generated_ids = inputs.input_ids[:, -1:]\n",
    "    for _ in range(max_new_tokens):\n",
    "        out = model(input_ids=generated_ids[:, -1:], past_key_values=new_past_kv, use_cache=True)\n",
    "        next_token = out.logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
    "        new_past_kv = out.past_key_values\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    result = tokenizer.decode(generated_ids[0, 1:], skip_special_tokens=True).strip()\n",
    "    \n",
    "    del outputs, past_kv, new_past_kv, attn\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strategies - all novel ones are cheap add-ons to RC\n",
    "strategies = {\n",
    "    \"FullKV\": None,\n",
    "    \"H2O\": H2OStrategy(budget_ratio=BUDGET_RATIO),\n",
    "    \"RC\": RCStrategy(budget_ratio=BUDGET_RATIO),\n",
    "    \"RC+HT\": RC_HittingTime(budget_ratio=BUDGET_RATIO),     # Novel: Hitting Time\n",
    "    \"RC+EP\": RC_EscapeProb(budget_ratio=BUDGET_RATIO),      # Novel: Escape Probability\n",
    "    \"RC+TM\": RC_TempMix(budget_ratio=BUDGET_RATIO),         # Novel: Temperature Mixing\n",
    "    \"RC+ALL\": RC_Combined(budget_ratio=BUDGET_RATIO),       # Novel: All combined\n",
    "}\n",
    "\n",
    "print(f\"Testing {len(strategies)} strategies on {len(samples)} samples\")\n",
    "print(\"\\nNovel modifications (zero extra CUDA kernel cost):\")\n",
    "print(\"- RC+HT: Hitting Time Weighting\")\n",
    "print(\"- RC+EP: Escape Probability\")\n",
    "print(\"- RC+TM: Temperature Mixing\")\n",
    "print(\"- RC+ALL: All combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {name: [] for name in strategies}\n",
    "\n",
    "for i, sample in enumerate(tqdm(samples)):\n",
    "    print(f\"\\n--- Sample {i+1} ---\")\n",
    "    print(f\"Q: {sample['question'][:80]}...\")\n",
    "    \n",
    "    for name, strategy in strategies.items():\n",
    "        try:\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            pred = generate_with_strategy(\n",
    "                model, tokenizer, sample[\"prompt\"],\n",
    "                strategy=strategy,\n",
    "                max_length=MAX_SEQ_LEN,\n",
    "                max_new_tokens=MAX_NEW_TOKENS,\n",
    "            )\n",
    "            \n",
    "            f1 = best_f1(pred, sample[\"answers\"])\n",
    "            results[name].append(f1)\n",
    "            print(f\"  {name:8s}: F1={f1:.3f} | {pred[:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {name}: ERROR - {e}\")\n",
    "            results[name].append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS: Novel RC Add-ons for ICML 2026\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "stats = {}\n",
    "for name, scores in results.items():\n",
    "    if scores:\n",
    "        stats[name] = {\"mean\": np.mean(scores), \"std\": np.std(scores)}\n",
    "\n",
    "sorted_names = sorted(stats.keys(), key=lambda x: stats[x][\"mean\"], reverse=True)\n",
    "fullkv_mean = stats.get(\"FullKV\", {}).get(\"mean\", 0)\n",
    "h2o_mean = stats.get(\"H2O\", {}).get(\"mean\", 0)\n",
    "rc_mean = stats.get(\"RC\", {}).get(\"mean\", 0)\n",
    "\n",
    "print(f\"\\n{'Strategy':<10} {'Mean F1':>10} {'vs RC':>10} {'vs H2O':>10} {'Novel?':>8}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "novel_markers = {\n",
    "    \"FullKV\": \"\",\n",
    "    \"H2O\": \"baseline\",\n",
    "    \"RC\": \"current\",\n",
    "    \"RC+HT\": \"NEW\",\n",
    "    \"RC+EP\": \"NEW\",\n",
    "    \"RC+TM\": \"NEW\",\n",
    "    \"RC+ALL\": \"NEW\",\n",
    "}\n",
    "\n",
    "for name in sorted_names:\n",
    "    s = stats[name]\n",
    "    diff_rc = s[\"mean\"] - rc_mean if name not in [\"FullKV\", \"H2O\", \"RC\"] else 0\n",
    "    diff_h2o = s[\"mean\"] - h2o_mean if name not in [\"FullKV\", \"H2O\"] else 0\n",
    "    \n",
    "    rc_str = f\"{diff_rc:+.3f}\" if diff_rc != 0 else \"---\"\n",
    "    h2o_str = f\"{diff_h2o:+.3f}\" if name not in [\"FullKV\", \"H2O\"] else \"---\"\n",
    "    \n",
    "    print(f\"{name:<10} {s['mean']:>10.3f} {rc_str:>10} {h2o_str:>10} {novel_markers.get(name, ''):>8}\")\n",
    "\n",
    "# Find best novel strategy\n",
    "novel_strategies = [\"RC+HT\", \"RC+EP\", \"RC+TM\", \"RC+ALL\"]\n",
    "best_novel = None\n",
    "best_novel_score = 0\n",
    "for name in novel_strategies:\n",
    "    if name in stats and stats[name][\"mean\"] > best_novel_score:\n",
    "        best_novel_score = stats[name][\"mean\"]\n",
    "        best_novel = name\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ICML 2026 RECOMMENDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if best_novel:\n",
    "    improvement_over_rc = best_novel_score - rc_mean\n",
    "    improvement_over_h2o = best_novel_score - h2o_mean\n",
    "    gap_to_full = fullkv_mean - best_novel_score\n",
    "    \n",
    "    print(f\"\\nBest NOVEL add-on: {best_novel}\")\n",
    "    print(f\"F1 score: {best_novel_score:.3f}\")\n",
    "    print(f\"Improvement over RC (current): {improvement_over_rc:+.3f}\")\n",
    "    print(f\"Improvement over H2O: {improvement_over_h2o:+.3f}\")\n",
    "    print(f\"Gap to FullKV: {gap_to_full:.3f}\")\n",
    "    \n",
    "    if improvement_over_rc > 0.02:\n",
    "        print(f\"\\n=> IMPLEMENT {best_novel} in CUDA kernel!\")\n",
    "        print(\"   This is a zero-cost improvement worth pursuing.\")\n",
    "    elif improvement_over_rc > 0:\n",
    "        print(f\"\\n=> MARGINAL: {best_novel} shows slight improvement. Run more samples.\")\n",
    "    else:\n",
    "        print(\"\\n=> Current RC is already optimal. Focus on other innovations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
